{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d817357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/anaconda3/envs/torchmd/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdescriptors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DihedralDescriptors, DistanceDescriptors, CoordinateDescriptors\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasis_set_bias\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasisBias\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgaussian_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridGaussians\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import ase\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from models.descriptors import DihedralDescriptors, DistanceDescriptors, CoordinateDescriptors\n",
    "\n",
    "from models.basis_set_bias import BasisBias\n",
    "from models.gaussian_models import GridGaussians\n",
    "\n",
    "from simulator.simple_diff_md import simulateNVTSystem, simulateNVTSystem_adjoint, simulateNVTSystem_warmup\n",
    "from simulator.descriptor_loss import DescriptorLoss\n",
    "from simulator.trainer import train_epoch\n",
    "from simulator.adjoint_provider import get_adjoints\n",
    "\n",
    "from plotting.plot_intermediate import plot_intermediate\n",
    "\n",
    "from scipy.stats import chi2\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\n",
    "parser.add_argument('--save_figs', action='store_true')\n",
    "parser.add_argument('--no_adjoint', action='store_true')\n",
    "parser.add_argument(\"--plot_every\", default=1, type=int, help=\"When to plot figures.\")\n",
    "\n",
    "# Main simulation parameters\n",
    "# Descriptor loss\n",
    "parser.add_argument(\"--iterations\", default=6000, type=int, help=\"Number of iterations to generate training data.\")\n",
    "parser.add_argument(\"--warmup\", default=1200, type=int, help=\"Warm-up period for the trajectory termalization\")\n",
    "parser.add_argument(\"--backsteps\", default=190, type=int, help=\"Number of backsteps. Must be smaller as warmup\")\n",
    "parser.add_argument(\"--plot_nth\", default=10, type=int, help=\"Plotting every nth point.\")\n",
    "\n",
    "\n",
    "parser.add_argument(\"--batch_size\", default=300, type=int, help=\"Batch size.\")\n",
    "parser.add_argument(\"--epochs\", default=100, type=int, help=\"Number of training epochs.\")\n",
    "parser.add_argument(\"--save_steps\", default=1, type=int, help=\"When to save tensor\")\n",
    "parser.add_argument(\"--dt\", default=1.0, type=float, help=\"Timestep in fs\")\n",
    "parser.add_argument(\"--barrier\", default=1.0, type=float, help=\"Barier size.\")\n",
    "parser.add_argument(\"--bias\", default=\"gauss\", type=str, help=\"Biased potential\")\n",
    "parser.add_argument(\"--dimension\", default=2, type=int, help=\"Biased potential\")\n",
    "parser.add_argument(\"--neurons\", default=150, type=int, help=\"Neurons in a net\")\n",
    "parser.add_argument(\"--loss\", default=\"quad\", type=str, help=\"Quadratic function\")\n",
    "parser.add_argument(\"--p_in_domain\", default=0.1, type=float, help=\"Tolerance to it the target.\")\n",
    "\n",
    "#Simulation controls\n",
    "parser.add_argument(\"--temperature\", default=10, type=float, help=\"System temperature.\")\n",
    "parser.add_argument(\"--gamma\", default=0.1, type=float, help=\"Friction in langevin.\")\n",
    "\n",
    "#Training parameters\n",
    "parser.add_argument(\"--learning_factor\", default=2.0, type=float, help=\"Learning rate.\")\n",
    "parser.add_argument(\"--mini_batch\", default=120, type=int, help=\"Mini batch\")\n",
    "parser.add_argument('--use_non_batched', action='store_true')\n",
    "parser.add_argument('--device', default=\"cuda:0\", type=str, help=\"Which device to use. CPU or GPU?\")\n",
    "parser.add_argument('--save_every_model', default=1, type=int, help=\"When to save the bias potential\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.save_figs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9317fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define som runtimes stuff    \n",
    "if args.save_steps > 1:\n",
    "    raise NotImplemented(\"Feature not yet implemented and tested\")\n",
    "\n",
    "args.warmup = args.warmup//args.save_steps\n",
    "args.backsteps = args.backsteps//args.save_steps\n",
    "\n",
    "#Distance d - arg of normal distribution follows chi2. We therefore consult scipy package and its chi2\n",
    "#implementation to get the actual d**2 tolerance so that P(x in X) >= p where p defined in args\n",
    "\n",
    "args.domain_tol = chi2.isf(args.p_in_domain, args.dimension)\n",
    "\n",
    "#The numerical stability factor. Adjoints tend to be too small and numerical accuracy is an issue. \n",
    "adjoint_multiplier = 1e4\n",
    "\n",
    "\n",
    "assert args.iterations > 3* args.warmup\n",
    "assert args.backsteps < args.warmup\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if args.no_adjoint:\n",
    "    forward_simulate = simulateNVTSystem\n",
    "else:\n",
    "    forward_simulate = simulateNVTSystem_adjoint\n",
    "\n",
    "\n",
    "first_checkpoint = False\n",
    "first_thr = 0.51\n",
    "second_checkpoint = False\n",
    "second_thr = 0.71\n",
    "#third_checkpoint = True\n",
    "#fourth_checkpoint = True\n",
    "\n",
    "\n",
    "args.folder = \"resultsMB/\"+args.loss+args.bias+ \"D\" + str(args.dimension)+\"I:\"+str(args.iterations) \\\n",
    "    + \"N\"+ str(args.neurons) + \"dt\" + str(args.dt) + \"T\" + str(args.temperature) + \"g\" \\\n",
    "    + str(args.gamma) +\"/\"\n",
    "isExist = os.path.exists(args.folder)\n",
    "\n",
    "if not isExist and (args.save_figs or args.save_every_model > 0):\n",
    "    os.makedirs(args.folder)\n",
    "    print(\"making folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c320d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell to design descriptors. \n",
    "\n",
    "if args.dimension == 2:\n",
    "    project_to = torch.tensor([0,1])\n",
    "elif args.dimension == 5:\n",
    "    project_to = torch.tensor([0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4195155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator.system import ToySystem\n",
    "from models.simpleMB import SimpleMB\n",
    "from functorch import vmap, jvp, vjp, grad\n",
    "\n",
    "\n",
    "potential = SimpleMB(args, n_in=args.dimension)\n",
    "\n",
    "M = 0.1*torch.ones(1, args.dimension)\n",
    "system = ToySystem(args.dimension, nreplicas=2*args.batch_size, masses=M, device=args.device)\n",
    "system.set_positions(potential.get_init_point(args.batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define initialization and setup the run\n",
    "from simulator.utils import maxwell_boltzmann, kinetic_energy, kinetic_to_temp, temp_to_kin\n",
    "\n",
    "desired_kin = temp_to_kin(300, args.dimension)\n",
    "    \n",
    "def get_init_point(steps = 300):\n",
    "\n",
    "    system.set_positions(potential.get_init_point(args.batch_size))\n",
    "    system.set_velocities(maxwell_boltzmann(system.M, args.temperature, args.dimension, replicas=2*args.batch_size))\n",
    "    kin = kinetic_energy(system.M, system.vel)\n",
    "\n",
    "    factor = torch.sqrt(desired_kin/kin).reshape(-1,1).repeat(1,args.dimension)\n",
    "    system.vel = system.vel*factor\n",
    "\n",
    "    system.to_(args.device)\n",
    "    #Pass a vmap on the non-biased forces\n",
    "    simulateNVTSystem_warmup(system, vmap(potential.force_func), args, steps=steps)\n",
    "    \n",
    "    kin = kinetic_energy(system.M, system.vel)\n",
    "\n",
    "    start, end = system.pos.detach().chunk(2,dim=0)\n",
    "    return system, torch.cat((start, end)), torch.cat((end, start))\n",
    "\n",
    "\n",
    "get_init_point(10)\n",
    "#Pass a vmap on a non-biased force\n",
    "pos_list = simulateNVTSystem_warmup(system, vmap(potential.force_func), args, steps=4200)\n",
    "#Stack the list of points and split into reactant trajs and product trajs\n",
    "pos_list = torch.stack(pos_list, axis=1)\n",
    "react_pos = pos_list[:args.batch_size]\n",
    "prod_pos = pos_list[args.batch_size:]\n",
    "\n",
    "coordinate_descriptors = CoordinateDescriptors()\n",
    "\n",
    "domain = {}\n",
    "domain[\"Lx\"], domain[\"Hx\"] = 10, 50\n",
    "domain[\"Ly\"], domain[\"Hy\"] = 0, 40\n",
    "domain[\"res\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.bias == \"gauss\":\n",
    "    height = 0.01\n",
    "    resolution = 50\n",
    "    var = 3**2\n",
    "    sample_bias_force = GridGaussians(height, args.dimension, -10, 55, resolution, var=var, descriptors=coordinate_descriptors, device=args.device)\n",
    "    if args.use_non_batched or args.no_adjoint:\n",
    "        lr = 0.001/adjoint_multiplier\n",
    "    else:\n",
    "        lr = 50*args.learning_factor/adjoint_multiplier/args.batch_size/10 \n",
    "        \n",
    "if args.bias == \"descriptor_basis\":   \n",
    "    \n",
    "    height = 0.01\n",
    "    resolution = 50\n",
    "    var = 25/10\n",
    "    sample_bias_force = BasisBias(height,args.dimension, -5, 55,\n",
    "                                       resolution=resolution, var=var, neurons=args.neurons,\n",
    "                                       descriptors=coordinate_descriptors, device=args.device)\n",
    "    if args.use_non_batched or args.no_adjoint:\n",
    "        lr = 0.1/adjoint_multiplier\n",
    "    else:\n",
    "        lr = args.learning_factor/adjoint_multiplier/args.batch_size         \n",
    "    \n",
    "    \n",
    "sample_bias_force.to(args.device)\n",
    "   \n",
    "#Adam optimizer seems to work the best\n",
    "optimizer = torch.optim.Adam(sample_bias_force.parameters(), lr=lr)\n",
    "\n",
    "#Since we update scheduler only \n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.3)\n",
    "\n",
    "#Descriptors\n",
    "#descriptor_loss = DescriptorLoss(coordinate_descriptors, react_var_inv, prod_var_inv, args)\n",
    "\n",
    "def sample_total_force(R):\n",
    "       \n",
    "    Epot, f_U = potential.force_func(R)   \n",
    "    f_b = sample_bias_force.force_func(R)\n",
    "    return f_U + f_b\n",
    "\n",
    "def get_forces_vjp(R, vec):\n",
    "    (_, vjpfunc) = vjp(sample_total_force, R)\n",
    "    grad = vjpfunc(vec)[0]\n",
    "    return grad\n",
    "\n",
    "\n",
    "vmaped_force = vmap(sample_total_force)\n",
    "vmaped_vjp = vmap(get_forces_vjp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7486992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory, _, _ = forward_simulate(system, vmaped_force, args)\n",
    "\n",
    "\n",
    "sample_bias_force.load_state_dict(torch.load(\"model65.pt\"))\n",
    "\n",
    "trajectory_conv, _, _ = forward_simulate(system, vmaped_force, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "\n",
    "tick_font_size = 14\n",
    "label_font_size = 18\n",
    "\n",
    "traj_tensor = torch.stack(trajectory, axis=1)\n",
    "traj_desc = coordinate_descriptors.get_descriptors(traj_tensor)   \n",
    "known_cvs = coordinate_descriptors.get_descriptors(traj_tensor)[...,project_to]\n",
    "\n",
    "\n",
    "Lx,Ly = domain[\"Lx\"], domain[\"Ly\"]\n",
    "Hx,Hy = domain[\"Hx\"], domain[\"Hy\"]\n",
    "resolution = domain[\"res\"]\n",
    "\n",
    "sample = traj_tensor[:,::args.plot_nth].reshape(-1, *traj_tensor.shape[2:])\n",
    "desc_sample = traj_desc[:,::args.plot_nth].reshape(-1, *traj_desc.shape[2:])\n",
    "cv_sample = known_cvs[:,::args.plot_nth].reshape(-1,2)\n",
    "\n",
    "x, y = torch.meshgrid(torch.linspace(Lx, Hx, resolution), torch.linspace(Ly, Hy, resolution), indexing='ij')\n",
    "x_dev, y_dev = x.to(args.device), y.to(args.device)\n",
    "\n",
    "plt.figure(figsize = (12,6)) \n",
    "plt.subplot(121)\n",
    "\n",
    "z = potential.U_split(x_dev, y_dev).reshape((resolution,resolution)).detach().cpu()\n",
    "pot = plt.pcolormesh(x, y, z, cmap='magma', vmin=z.min(), vmax=10, shading='auto')\n",
    "#cbar = plt.colorbar(pot, location=\"left\")\n",
    "#cbar.ax.set_ylabel('Potential [kcal/mol]',fontsize=13)\n",
    "\n",
    "#plt.xlabel(\"x\")\n",
    "plt.axis([Lx, Hx, Ly, Hy])\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "plt.hexbin(cv_sample[:,0], cv_sample[:,1].detach().cpu(), bins=\"log\", alpha=alpha, cmap=\"viridis\",gridsize=40, mincnt=5)\n",
    "#plt.hexbin(cv_sample[:,0], cv_sample[:,1].detach().cpu(), bins=None, alpha=alpha, cmap=\"viridis\",gridsize=40, mincnt=5)\n",
    "\n",
    "cbar = plt.colorbar(location=\"left\")\n",
    "cbar.ax.tick_params(labelsize=tick_font_size)\n",
    "cbar.ax.set_ylabel('Unbiased sampling - log-density',fontsize=label_font_size)\n",
    "plt.axis([Lx, Hx, Ly, Hy])\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    right=False,\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "traj_tensor = torch.stack(trajectory_conv, axis=1)\n",
    "traj_desc = coordinate_descriptors.get_descriptors(traj_tensor)   \n",
    "known_cvs = coordinate_descriptors.get_descriptors(traj_tensor)[...,project_to]\n",
    "\n",
    "sample = traj_tensor[:,::args.plot_nth].reshape(-1, *traj_tensor.shape[2:])\n",
    "desc_sample = traj_desc[:,::args.plot_nth].reshape(-1, *traj_desc.shape[2:])\n",
    "cv_sample = known_cvs[:,::args.plot_nth].reshape(-1,2)\n",
    "\n",
    "x, y = torch.meshgrid(torch.linspace(Lx, Hx, resolution), torch.linspace(Ly, Hy, resolution), indexing='ij')\n",
    "x_dev, y_dev = x.to(args.device), y.to(args.device)\n",
    "\n",
    "z = potential.U_split(x_dev, y_dev).reshape((resolution,resolution)).detach().cpu()\n",
    "pot = plt.pcolormesh(x, y, z, cmap='magma', vmin=z.min(), vmax=10, shading='auto')\n",
    "#cbar = plt.colorbar(pot, location=\"left\")\n",
    "#cbar.ax.set_ylabel('Potential [kcal/mol]',fontsize=13)\n",
    "\n",
    "#plt.xlabel(\"x\")\n",
    "plt.axis([Lx, Hx, Ly, Hy])\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "plt.hexbin(cv_sample[:,0], cv_sample[:,1].detach().cpu(), bins=\"log\", alpha=alpha, cmap=\"viridis\",gridsize=40, mincnt=5)\n",
    "#plt.hexbin(cv_sample[:,0], cv_sample[:,1].detach().cpu(), bins=None, alpha=alpha, cmap=\"viridis\",gridsize=40, mincnt=5)\n",
    "#cbar2 = plt.colorbar(location=\"right\")\n",
    "cbar2.ax.tick_params(labelsize=tick_font_size)\n",
    "cbar2.ax.set_ylabel('Biased sampling - log-density',fontsize=label_font_size)\n",
    "plt.axis([Lx, Hx, Ly, Hy])\n",
    "\n",
    "#plt.ylabel(\"y\")\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    right=False,\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.savefig(\"initial_density\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05493806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baca7af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchmdproj",
   "language": "python",
   "name": "torchmdproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
